{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Start of training\n",
        "this logs info about the runtime then downloads the kaggle datset using my kaggle key.\n",
        "\n",
        "**THIS MUST BE DONE EACH TIME THE RUNTIME IS STARTED OVER.**\n",
        "It is tedious but the images must be in the runtime memory to be fast enough.\n",
        "\n",
        "i am storing my runs in the document **DAT255 notes > DAT255 RUNS**. Here i write what changes i am doing, often why and what the results were."
      ],
      "metadata": {
        "id": "uOl13mS8ZTtJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRvAtYUREfIT",
        "outputId": "ffd94e27-5134-439f-ba8a-090ad3f81245",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Apr 21 09:03:05 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers, preprocessing\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!echo '{\"username\":\"vegardaaalbretsen\",\"key\":\"18f385007d1223dd35dc94f16e311545\"}' > ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "#!kaggle datasets download -d puneet6060/intel-image-classification\n",
        "#!unzip intel-image-classification.zip -d /content/dataset\n",
        "\n",
        "#!kaggle datasets download -d seryouxblaster764/fgvc-aircraft\n",
        "#!unzip fgvc-aircraft.zip -d /content/dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d tusonggao/imagenet-train-subset-100k --unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-gjQbZ3Y7lv",
        "outputId": "2dde8563-c57d-4083-e189-af82c1c734b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/tusonggao/imagenet-train-subset-100k\n",
            "License(s): unknown\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What am i typically changing?\n",
        "first and foremost learning rate with different schedulers and epochs.\n",
        "after that there has been a lot of fiddling with augmentation, image resolution (which then often pushes the ram requirements). Higher resolution often requires smaller model, smaller batch size and such.\n",
        "\n",
        "\n",
        "### What would I do?\n",
        "I would maybe try to find some architecture (like densenet or something) and try to alter my model a bit. I feel like this architecture with this size wont get that much better than 60%.\n",
        "\n",
        "You could also increase depth and reduce width (base amount of filters) or the opposite. I have an idea that more depth (to capture more advanced features) might be beneficial."
      ],
      "metadata": {
        "id": "yGJAWLfwcERI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image preprocessing\n",
        "Here you have image resolution, batch size and augmentation.\n",
        "The problem with augmentation (and dropout/regularization) is that the line between too little and too much is tight.\n",
        "\n",
        "### HOW TO KNOW WHEN TO INCREASE/DECREASE AUGMENTATION/REGULARIZATION\n",
        "Overfitting = Accuracy >> validation accuracy ==> **YOU CAN INCREASE A BIT**\n",
        "Not learning = Accuracy == Validation accuracy == 0.01 ==> **DECREASE AUGMENTATION/REGULARIZATION**\n",
        "\n",
        "Remember to monitor this DURING the run, because suddenly you have ran for 2 hrs and it still is 0.01 accuracy.\n",
        "\n",
        "I feel like the the line between these two are difficult, and i have either accuracy 20 percentage-points above val accuracy at the end, or it is not learning."
      ],
      "metadata": {
        "id": "_t2haVOdYIya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n"
      ],
      "metadata": {
        "id": "f5FfL0bnXDaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I77lxljLXEXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers, preprocessing\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Define the path to the dataset\n",
        "dataset_path = '/content/dataset'\n",
        "image_path = '/content/dataset/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images'\n",
        "\n",
        "# Load CSV files\n",
        "train_df = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\n",
        "val_df = pd.read_csv(os.path.join(dataset_path, 'val.csv'))\n",
        "test_df = pd.read_csv(os.path.join(dataset_path, 'test.csv'))\n",
        "\n",
        "# Add full image paths to DataFrames\n",
        "train_df['filepath'] = train_df['filename'].apply(lambda x: os.path.join(image_path, x))\n",
        "val_df['filepath'] = val_df['filename'].apply(lambda x: os.path.join(image_path, x))\n",
        "test_df['filepath'] = test_df['filename'].apply(lambda x: os.path.join(image_path, x))\n",
        "\n",
        "# Convert class labels to categorical\n",
        "train_df['Labels'] = train_df['Labels'].astype(str)\n",
        "val_df['Labels'] = val_df['Labels'].astype(str)\n",
        "test_df['Labels'] = test_df['Labels'].astype(str)\n",
        "\n",
        "# Image and Batch size\n",
        "img_size = (370,540)\n",
        "batch_size = 24\n",
        "\n",
        "# THIS IS TOO MUCH\n",
        "# can experiment with https://keras.io/api/layers/preprocessing_layers/\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.05),  # Reduced rotation factor\n",
        "    layers.RandomZoom(0.1),  # Reduced zoom factor\n",
        "    layers.RandomTranslation(0.05, 0.05),  # Reduced translation factor\n",
        "    layers.RandomContrast(0.1),  # Reduced contrast factor\n",
        "    layers.RandomBrightness(0.1),  # Reduced brightness factor\n",
        "    layers.RandomCrop(360, 520),  # Slightly larger crop size to reduce cropping effect\n",
        "])\n",
        "\n",
        "def load_and_augment_image1(image_path, label):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = img[:-12, :, :]  # Remove the black line on the bottom\n",
        "    img = tf.image.resize(img, img_size) / 255.0  # Normalize\n",
        "    label = tf.reshape(label, [])\n",
        "\n",
        "    img = data_augmentation(img)  # Apply data augmentation\n",
        "    img = tf.image.resize(img, img_size)  # Resize Back\n",
        "\n",
        "    return img, label\n",
        "\n",
        "# Function to load and preprocess images with augmentation for training\n",
        "def load_and_augment_image(image_path, label):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = img[:-12, :, :]  #Remove the black line on the bottom\n",
        "    img = tf.image.resize(img, img_size) / 255.0  # Normalize\n",
        "    label = tf.reshape(label, [])\n",
        "\n",
        "    # Apply Data Augmentation\n",
        "    img = tf.image.random_flip_left_right(img)\n",
        "    img = tf.image.random_brightness(img, max_delta=0.2)\n",
        "    img = tf.image.random_contrast(img, lower=0.8, upper=1.2)\n",
        "    img = tf.image.random_saturation(img, lower=0.85, upper=1.1)\n",
        "    img = tf.image.random_hue(img, max_delta=0.0125)\n",
        "\n",
        "\n",
        "    # **Additional Transformations**\n",
        "    img = tf.image.random_crop(img, size=[350, 500, 3])  # âœ… Random Cropping (optional)\n",
        "    img = tf.image.resize(img, img_size)  # Resize Back\n",
        "\n",
        "    return img, label\n",
        "\n",
        "# Function to load images without augmentation for validation/testing\n",
        "def load_image(image_path, label):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = img[:-12, :, :]  # Remove the black line on the bottom\n",
        "    img = tf.image.resize(img, img_size) / 255.0  # Normalize\n",
        "    label = tf.reshape(label, [])\n",
        "    return img, label\n",
        "\n",
        "# Convert DataFrames to TensorFlow datasets\n",
        "def dataframe_to_dataset(df, batch_size=batch_size, shuffle=True, augment=False):\n",
        "    file_paths = df['filepath'].values\n",
        "    labels = df['Labels'].astype('category').cat.codes.values  # Convert labels to numerical format\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
        "\n",
        "    if augment:\n",
        "        dataset = dataset.map(lambda x, y: load_and_augment_image(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda x, y: load_image(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(len(df))\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(2)  # Ensure consistency\n",
        "    return dataset\n",
        "\n",
        "# Create datasets using tf.data pipeline with augmentation for training\n",
        "train_airplane = dataframe_to_dataset(train_df, batch_size=batch_size, augment=True)\n",
        "val_airplane = dataframe_to_dataset(val_df, batch_size=batch_size, shuffle=False, augment=False)\n",
        "test_airplane = dataframe_to_dataset(test_df, batch_size=batch_size, shuffle=False, augment=False)"
      ],
      "metadata": {
        "id": "KsOOcGSsFYLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Once used to log the distribution of resolutions\n",
        "not necessary"
      ],
      "metadata": {
        "id": "0fJllLLYXJbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the path to the dataset\n",
        "image_path = '/content/dataset/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images'\n",
        "\n",
        "# Initialize a list to store image dimensions\n",
        "image_dimensions = []\n",
        "\n",
        "# Iterate through each image file in the dataset\n",
        "for filename in os.listdir(image_path):\n",
        "    if filename.endswith('.jpg'):  # Ensure the file is an image\n",
        "        with Image.open(os.path.join(image_path, filename)) as img:\n",
        "            width, height = img.size\n",
        "            image_dimensions.append((width, height))\n",
        "\n",
        "# Convert the list to a DataFrame for analysis\n",
        "df = pd.DataFrame(image_dimensions, columns=['Width', 'Height'])\n",
        "\n",
        "# Calculate minimum and maximum resolutions\n",
        "min_resolution = df.min()\n",
        "max_resolution = df.max()\n",
        "\n",
        "print(f\"Minimum Resolution: {min_resolution['Width']}x{min_resolution['Height']}\")\n",
        "print(f\"Maximum Resolution: {max_resolution['Width']}x{max_resolution['Height']}\")\n",
        "\n",
        "# Plot the distribution of image resolutions\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(df['Width'], df['Height'], alpha=0.5, edgecolors='w', linewidth=0.5)\n",
        "plt.title('Distribution of Image Resolutions')\n",
        "plt.xlabel('Width (pixels)')\n",
        "plt.ylabel('Height (pixels)')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQRTTbmW8Udv",
        "outputId": "8c272d43-8d69-44da-92f6-37d73051b0aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum Resolution: 775x413\n",
            "Maximum Resolution: 1600x1205\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relu6 activation function\n",
        "Not currently in use, swap all activation layers that currently are layers.Activation(tf.nn.silu) for layers.Activation(\"relu6\") to use."
      ],
      "metadata": {
        "id": "qM1uuDnLSR7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu6(x):\n",
        "    return tf.nn.relu6(x)"
      ],
      "metadata": {
        "id": "sJXPV2N3Fjzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Squeeze and exitation module\n",
        "This is a part of the more recent mobilenet architectures, V2 or V3 i think.\n",
        "\n",
        "The SE block, however, introduces an adaptive approach where the importance of each channel is individually assessed based on its context. In simpler terms, the SE block takes into account the relevance of each channel when computing the output.\n",
        "\n",
        "https://medium.com/@tahasamavati/squeeze-and-excitation-explained-387b5981f249"
      ],
      "metadata": {
        "id": "OOdYDqxdSiNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def se_module(inputs, reduction=4):\n",
        "    input_channels = inputs.shape[-1]\n",
        "    reduced_channels = input_channels // reduction\n",
        "\n",
        "    se = layers.GlobalAveragePooling2D()(inputs)\n",
        "    se = layers.Reshape((1, 1, input_channels))(se)\n",
        "    se = layers.Dense(reduced_channels, activation='relu')(se)\n",
        "    se = layers.Dense(input_channels, activation='sigmoid')(se)\n",
        "    return layers.multiply([inputs, se])"
      ],
      "metadata": {
        "id": "qXbEN-EpYIKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stochastic depth layer\n",
        "Has a probability *p* to be dropped, but only during training.  \n",
        "This is supposed to prevent the model from relying too much on any one feature"
      ],
      "metadata": {
        "id": "mv1AZbmnuHWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.keras.utils.register_keras_serializable()\n",
        "class StochasticDepth(tf.keras.layers.Layer):\n",
        "    def __init__(self, drop_prob=0.2, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        if training:\n",
        "            keep_prob = 1.0 - self.drop_prob\n",
        "            batch_size = tf.shape(inputs)[0]\n",
        "            random_tensor = keep_prob + tf.random.uniform([batch_size, 1, 1, 1], dtype=inputs.dtype)\n",
        "            binary_tensor = tf.floor(random_tensor)  # Convert to 0 or 1\n",
        "            return inputs * binary_tensor / keep_prob  # Scale for variance correction\n",
        "        return inputs\n"
      ],
      "metadata": {
        "id": "Hh_wuLgDuGcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standard MobileNetV2 Inverted Residual block\n",
        "With an added stochastic-depth block\n"
      ],
      "metadata": {
        "id": "OtJ6FZ-ZYjtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inverted_residual_block(inputs, expansion_factor, output_channels, stride, use_se=True, dropout_rate=0.175, drop_prob=0.2, dilation_rate=1):\n",
        "    input_channels = inputs.shape[-1]\n",
        "    expanded_channels = input_channels * expansion_factor\n",
        "\n",
        "    # Expansion Phase\n",
        "    x = layers.Conv2D(expanded_channels, kernel_size=1, padding='same', use_bias=False)(inputs)\n",
        "    x = layers.Activation(tf.nn.silu)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Depthwise Convolution\n",
        "    x = layers.DepthwiseConv2D(kernel_size=3, strides=stride, padding='same', dilation_rate=dilation_rate, use_bias=False)(x)\n",
        "    x = layers.Activation(tf.nn.silu)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Squeeze-and-Excitation Module (Optional)\n",
        "    if use_se:\n",
        "        x = se_module(x)\n",
        "\n",
        "    # Dropout to reduce overfitting\n",
        "    x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Projection Phase\n",
        "    x = layers.Conv2D(output_channels, kernel_size=1, padding='same', use_bias=False, kernel_regularizer=l2(1e-4))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # âœ… Apply Stochastic Depth before residual connection\n",
        "    x = StochasticDepth(drop_prob=drop_prob)(x)\n",
        "\n",
        "\n",
        "    # Residual Connection\n",
        "    if stride == 1 and input_channels == output_channels:\n",
        "        x = layers.add([inputs, x])\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "u_ezNvR8YpOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regular residual block with stochastic depth\n",
        "This is not in use. I used this to compare the two.\n"
      ],
      "metadata": {
        "id": "x8QO2yf2uKGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "def residual_block(inputs, output_channels, stride=1, use_se=True, dropout_rate=0.15, drop_prob=0.2):\n",
        "    input_channels = inputs.shape[-1]\n",
        "\n",
        "    # First Convolution\n",
        "    x = layers.Conv2D(output_channels, kernel_size=3, strides=stride, padding='same', use_bias=False)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    # Second Convolution\n",
        "    x = layers.Conv2D(output_channels, kernel_size=3, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Squeeze-and-Excitation Module (Optional)\n",
        "    if use_se:\n",
        "        x = se_module(x)\n",
        "\n",
        "    # Dropout to reduce overfitting\n",
        "    x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Apply Stochastic Depth before residual connection\n",
        "    x = StochasticDepth(drop_prob=drop_prob)(x)\n",
        "\n",
        "    # Residual Connection\n",
        "    if stride == 1 and input_channels == output_channels:\n",
        "        x = layers.add([inputs, x])\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "CIbrmScxuJoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Efficientnet scaling\n",
        "We use a compound scaling coefficient (Ï•) to scale:\n",
        "\n",
        "- Depth (number of blocks)\n",
        "- Width (number of filters)\n",
        "- Resolution (input image size)\n",
        "\n",
        "This should scale the model dynamically in an EfficientNet- manner\n",
        "\n",
        "This is kinda pointless, since the model gets too big too fast if i use anything other than 0"
      ],
      "metadata": {
        "id": "XP-nPG-nZ1ZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_parameters(base_depth, base_width, phi, alpha=1.2, beta=1.1, gamma=1.15):\n",
        "    depth = int(base_depth * alpha ** phi)\n",
        "    width = int(base_width * beta ** phi)\n",
        "    return depth, width\n"
      ],
      "metadata": {
        "id": "Mr1rGhWSZ3Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the model\n",
        "This is set up in a dynamiaclly scaling way\n",
        "\n",
        "Here we can change the ratio of base depth and width. Remember that we can also scale the model when using the build_scaled_model function but if the depth and width stay the same, the shape of the model will be the same, if that makes sense"
      ],
      "metadata": {
        "id": "cmu6rPvTaPhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "def build_scaled_model(phi, input_shape=(370,540, 3), num_classes=100):\n",
        "    base_depth = 4   # Number of IR blocks per stage\n",
        "    base_width = 112  # Initial number of filters\n",
        "\n",
        "    depth, width = scale_parameters(base_depth, base_width, phi)\n",
        "\n",
        "    inputs = layers.Input(shape=(370,540,3))\n",
        "\n",
        "    # Initial Conv Layer\n",
        "    x = layers.Conv2D(width, kernel_size=3, strides=2, padding='same', use_bias=False)(inputs)\n",
        "    x = layers.Activation(tf.nn.silu)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Stacking Inverted Residual Blocks with Scaling & Stochastic Depth\n",
        "    for i in range(depth):\n",
        "        stride = 1 if i > 0 else 2  # Stride 2 for first block in each stage\n",
        "        drop_prob = min(0.05 + (0.02 * i), 0.2)\n",
        "        dilation_rate = 2 if i == depth - 1 else 1  # Increase dilation rate for the last block\n",
        "        x = inverted_residual_block(x,\n",
        "                                    expansion_factor=4,\n",
        "                                    output_channels=width,\n",
        "                                    stride=stride,\n",
        "                                    use_se=True,\n",
        "                                    drop_prob=drop_prob,\n",
        "                                    dilation_rate=dilation_rate)\n",
        "        width *= 2  # Increase filters at each stage\n",
        "\n",
        "    # Final Global Pooling and Classifier\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, x)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "5OMTM0dpaPE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the model\n",
        "Now we can build different size models by adjusting the phi\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Under i am doing a summary of the model. This is used to assess how big of a difference the change i made had.\n"
      ],
      "metadata": {
        "id": "vfwNWeBOamF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_model = build_scaled_model(phi=0)  # Small\n",
        "#medium_model = build_scaled_model(phi=1) # medium\n"
      ],
      "metadata": {
        "id": "aB5wShkvasdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_model.summary()\n",
        "print(len(small_model.layers))\n",
        "#medium_model.summary()\n",
        "#large_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g-h4LPH7atAV",
        "outputId": "0539ac1a-151a-45d8-914f-515fbe8977dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_3             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m370\u001b[0m, \u001b[38;5;34m540\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ -                      â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m185\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m112\u001b[0m)  â”‚          \u001b[38;5;34m3,024\u001b[0m â”‚ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_9 (\u001b[38;5;33mActivation\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m185\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m112\u001b[0m)  â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_13    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m185\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m112\u001b[0m)  â”‚            \u001b[38;5;34m448\u001b[0m â”‚ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m185\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m448\u001b[0m)  â”‚         \u001b[38;5;34m50,176\u001b[0m â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_10             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m185\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m448\u001b[0m)  â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_14    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m185\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m448\u001b[0m)  â”‚          \u001b[38;5;34m1,792\u001b[0m â”‚ activation_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d_4        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m448\u001b[0m)   â”‚          \u001b[38;5;34m4,032\u001b[0m â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_11             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m448\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ depthwise_conv2d_4[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_15    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m448\u001b[0m)   â”‚          \u001b[38;5;34m1,792\u001b[0m â”‚ activation_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2dâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m)            â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_4 (\u001b[38;5;33mReshape\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m448\u001b[0m)      â”‚              \u001b[38;5;34m0\u001b[0m â”‚ global_average_poolinâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m112\u001b[0m)      â”‚         \u001b[38;5;34m50,288\u001b[0m â”‚ reshape_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_10 (\u001b[38;5;33mDense\u001b[0m)          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m448\u001b[0m)      â”‚         \u001b[38;5;34m50,624\u001b[0m â”‚ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_4 (\u001b[38;5;33mMultiply\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m448\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m448\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ multiply_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m112\u001b[0m)   â”‚         \u001b[38;5;34m50,176\u001b[0m â”‚ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_16    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m112\u001b[0m)   â”‚            \u001b[38;5;34m448\u001b[0m â”‚ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ stochastic_depth_4        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m112\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mStochasticDepth\u001b[0m)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m448\u001b[0m)   â”‚         \u001b[38;5;34m50,176\u001b[0m â”‚ stochastic_depth_4[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_12             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m448\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_17    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m448\u001b[0m)   â”‚          \u001b[38;5;34m1,792\u001b[0m â”‚ activation_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d_5        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m448\u001b[0m)   â”‚          \u001b[38;5;34m4,032\u001b[0m â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_13             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m448\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ depthwise_conv2d_5[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_18    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m448\u001b[0m)   â”‚          \u001b[38;5;34m1,792\u001b[0m â”‚ activation_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2dâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m)            â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_5 (\u001b[38;5;33mReshape\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m448\u001b[0m)      â”‚              \u001b[38;5;34m0\u001b[0m â”‚ global_average_poolinâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_11 (\u001b[38;5;33mDense\u001b[0m)          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m112\u001b[0m)      â”‚         \u001b[38;5;34m50,288\u001b[0m â”‚ reshape_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_12 (\u001b[38;5;33mDense\u001b[0m)          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m448\u001b[0m)      â”‚         \u001b[38;5;34m50,624\u001b[0m â”‚ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_5 (\u001b[38;5;33mMultiply\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m448\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m448\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ multiply_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m224\u001b[0m)   â”‚        \u001b[38;5;34m100,352\u001b[0m â”‚ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_19    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m224\u001b[0m)   â”‚            \u001b[38;5;34m896\u001b[0m â”‚ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ stochastic_depth_5        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m224\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mStochasticDepth\u001b[0m)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m896\u001b[0m)   â”‚        \u001b[38;5;34m200,704\u001b[0m â”‚ stochastic_depth_5[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_14             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m896\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_20    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m896\u001b[0m)   â”‚          \u001b[38;5;34m3,584\u001b[0m â”‚ activation_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d_6        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m896\u001b[0m)   â”‚          \u001b[38;5;34m8,064\u001b[0m â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_15             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m896\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ depthwise_conv2d_6[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_21    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m896\u001b[0m)   â”‚          \u001b[38;5;34m3,584\u001b[0m â”‚ activation_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2dâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m896\u001b[0m)            â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_6 (\u001b[38;5;33mReshape\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m896\u001b[0m)      â”‚              \u001b[38;5;34m0\u001b[0m â”‚ global_average_poolinâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_13 (\u001b[38;5;33mDense\u001b[0m)          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m224\u001b[0m)      â”‚        \u001b[38;5;34m200,928\u001b[0m â”‚ reshape_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_14 (\u001b[38;5;33mDense\u001b[0m)          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m896\u001b[0m)      â”‚        \u001b[38;5;34m201,600\u001b[0m â”‚ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_6 (\u001b[38;5;33mMultiply\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m896\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m896\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ multiply_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m448\u001b[0m)   â”‚        \u001b[38;5;34m401,408\u001b[0m â”‚ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_22    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m448\u001b[0m)   â”‚          \u001b[38;5;34m1,792\u001b[0m â”‚ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ stochastic_depth_6        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m448\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mStochasticDepth\u001b[0m)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m1792\u001b[0m)  â”‚        \u001b[38;5;34m802,816\u001b[0m â”‚ stochastic_depth_6[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_16             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m1792\u001b[0m)  â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_23    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m1792\u001b[0m)  â”‚          \u001b[38;5;34m7,168\u001b[0m â”‚ activation_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d_7        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m1792\u001b[0m)  â”‚         \u001b[38;5;34m16,128\u001b[0m â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_17             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m1792\u001b[0m)  â”‚              \u001b[38;5;34m0\u001b[0m â”‚ depthwise_conv2d_7[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_24    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m1792\u001b[0m)  â”‚          \u001b[38;5;34m7,168\u001b[0m â”‚ activation_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2dâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1792\u001b[0m)           â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_7 (\u001b[38;5;33mReshape\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1792\u001b[0m)     â”‚              \u001b[38;5;34m0\u001b[0m â”‚ global_average_poolinâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_15 (\u001b[38;5;33mDense\u001b[0m)          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m448\u001b[0m)      â”‚        \u001b[38;5;34m803,264\u001b[0m â”‚ reshape_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_16 (\u001b[38;5;33mDense\u001b[0m)          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1792\u001b[0m)     â”‚        \u001b[38;5;34m804,608\u001b[0m â”‚ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_7 (\u001b[38;5;33mMultiply\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m1792\u001b[0m)  â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m1792\u001b[0m)  â”‚              \u001b[38;5;34m0\u001b[0m â”‚ multiply_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m896\u001b[0m)   â”‚      \u001b[38;5;34m1,605,632\u001b[0m â”‚ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_25    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m896\u001b[0m)   â”‚          \u001b[38;5;34m3,584\u001b[0m â”‚ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ stochastic_depth_7        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m135\u001b[0m, \u001b[38;5;34m896\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mStochasticDepth\u001b[0m)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2dâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m896\u001b[0m)            â”‚              \u001b[38;5;34m0\u001b[0m â”‚ stochastic_depth_7[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_17 (\u001b[38;5;33mDense\u001b[0m)          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            â”‚         \u001b[38;5;34m89,700\u001b[0m â”‚ global_average_poolinâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)              </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">        Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to           </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_3             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">370</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">540</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,024</span> â”‚ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)  â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_13    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)  â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> â”‚ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)  â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">50,176</span> â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_10             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)  â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_14    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> â”‚ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d_4        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,032</span> â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_11             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ depthwise_conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_15    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> â”‚ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2dâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)            â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)      â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_poolinâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)      â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">50,288</span> â”‚ reshape_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)      â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">50,624</span> â”‚ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multiply_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)   â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">50,176</span> â”‚ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_16    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)   â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> â”‚ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ stochastic_depth_4        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">StochasticDepth</span>)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)   â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">50,176</span> â”‚ stochastic_depth_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_12             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_17    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> â”‚ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d_5        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,032</span> â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_13             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ depthwise_conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_18    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> â”‚ activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2dâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)            â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)      â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_poolinâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)      â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">50,288</span> â”‚ reshape_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)      â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">50,624</span> â”‚ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multiply_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">100,352</span> â”‚ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_19    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)   â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> â”‚ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ stochastic_depth_5        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">StochasticDepth</span>)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">200,704</span> â”‚ stochastic_depth_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_14             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_20    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> â”‚ activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d_6        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,064</span> â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_15             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ depthwise_conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_21    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> â”‚ activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2dâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)            â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)      â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_poolinâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)      â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">200,928</span> â”‚ reshape_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)      â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">201,600</span> â”‚ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multiply_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">401,408</span> â”‚ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_22    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> â”‚ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ stochastic_depth_6        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">StochasticDepth</span>)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">802,816</span> â”‚ stochastic_depth_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_16             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)  â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_23    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,168</span> â”‚ activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d_7        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)  â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,128</span> â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_17             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)  â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ depthwise_conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_24    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,168</span> â”‚ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2dâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)           â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)     â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_poolinâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)      â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">803,264</span> â”‚ reshape_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)     â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">804,608</span> â”‚ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)  â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)  â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multiply_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)   â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605,632</span> â”‚ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_25    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> â”‚ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ stochastic_depth_7        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">StochasticDepth</span>)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2dâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)            â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ stochastic_depth_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">89,700</span> â”‚ global_average_poolinâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,634,484\u001b[0m (21.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,634,484</span> (21.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,616,564\u001b[0m (21.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,616,564</span> (21.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m17,920\u001b[0m (70.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,920</span> (70.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosine Annealing scheduler like efficientnet\n",
        "This is a learning rate scheduler that reduces the learning rate gradually over time instead of dropping it suddenly.\n",
        "probably good."
      ],
      "metadata": {
        "id": "ZTnavwnbf6aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_annealing(epoch, lr):\n",
        "    min_lr = 1e-7  # Raise this a bit (previously 1e-6)\n",
        "    max_lr = 4.5e-4  # Slightly higher than before\n",
        "    T_max = 150  # Stretch over 200 epochs for slower decay\n",
        "\n",
        "    new_lr = min_lr + (max_lr - min_lr) * (1 + tf.math.cos(epoch / T_max * 3.141592653589793)) / 2\n",
        "    return float(new_lr)\n"
      ],
      "metadata": {
        "id": "EMWwCmW_f5pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Cycle learning rate scheduling\n",
        "i gathered this from the pensumbok and it has worked well.\n",
        "Doesnt work with early stopping since it works its way up in LR then back down."
      ],
      "metadata": {
        "id": "G5OOmTu2UQTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Nadam\n",
        "\n",
        "total_epochs = 150\n",
        "initial_lr = 4.5e-4\n",
        "max_lr = 4.5e-3\n",
        "min_lr = 1e-7\n",
        "\n",
        "optimizer = Nadam(learning_rate=initial_lr, clipnorm=1.0)\n",
        "\n",
        "# Implement the 1cycle learning rate policy\n",
        "def lr_schedule(epoch, lr):\n",
        "    if epoch < total_epochs * 0.33:  # Ramp-up (0-33%)\n",
        "        lr = initial_lr + (max_lr - initial_lr) * (epoch / (total_epochs * 0.33))\n",
        "    elif epoch < total_epochs * 0.8:  # Ramp-down (33-80%)\n",
        "        lr = max_lr - (max_lr - initial_lr) * ((epoch - total_epochs * 0.33) / (total_epochs * 0.47))\n",
        "    else:  # Final decay (80-100%)\n",
        "        lr = initial_lr - (initial_lr - min_lr) * ((epoch - total_epochs * 0.8) / (total_epochs * 0.2))\n",
        "        lr = max(lr, min_lr)  # Ensure lr does not go below min_lr\n",
        "    return lr\n",
        "\n",
        "# Callbacks\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n"
      ],
      "metadata": {
        "id": "i08FV18u5Zxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialization of the cosine annealing scheduler, early stopping and reduceLROnPlateau. These have the option to \"start_from_epoch\" so that they can be used together with a scheduler like 1cycle, allthough reduceLROnPlateau wont be necessary with another lr scheduler as its already handling the lr.\n",
        "\n",
        "Can also be set to monitor accuracy, but then also \"mode='max'\" since that is a maximation problem."
      ],
      "metadata": {
        "id": "wDUhuDArUeQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(cosine_annealing, verbose=1)\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", patience=15, restore_best_weights=True, start_from_epoch=50, mode='min'\n",
        ")\n",
        "#Reduces Learning rate on plateau\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-7, start_from_epoch=50, mode='min'\n",
        ")\n"
      ],
      "metadata": {
        "id": "edc4l0W1-A19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manual scheduler\n",
        "Made a manual scheduler because i thought i was smart.\n",
        "I wasnt."
      ],
      "metadata": {
        "id": "yxX6-bPhVFTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def manual_lr_schedule(epoch, lr):\n",
        "    if epoch > 100:\n",
        "        lr = 2e-3\n",
        "    elif epoch > 80:\n",
        "        lr = 2.5e-3\n",
        "    elif epoch > 60:\n",
        "        lr = 3e-3\n",
        "    elif epoch > 40:\n",
        "        lr = 3.5e-3\n",
        "    elif epoch > 20:\n",
        "        lr = 4e-3\n",
        "    return lr\n",
        "\n",
        "\n",
        "#lr_scheduler = tf.keras.callbacks.LearningRateScheduler(manual_lr_schedule)"
      ],
      "metadata": {
        "id": "3IuTNpJnUgFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradual warmup scheduler\n",
        "Used to check the \"optimal learning rate\" for a model. you can run this and see when it takes a turn for the worse in loss and accuracy and that will be the optimal learning rate.\n",
        "Idea is taken from the pensumbok"
      ],
      "metadata": {
        "id": "Rkjq1TrSVK1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def gradual_warmup_scheduler(epoch, start_lr=1e-6, end_lr=1e-3, num_epochs=40):\n",
        "    \"\"\"Linearly increases learning rate from start_lr to end_lr over num_epochs.\"\"\"\n",
        "    lrs = np.linspace(start_lr, end_lr, num=num_epochs)\n",
        "    return lrs[min(epoch, num_epochs - 1)]  # Ensure it doesn't go beyond num_epochs\n",
        "\n",
        "# Create a callback for model.fit()\n",
        "lr_warmscheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: gradual_warmup_scheduler(epoch, 1e-7, 1e-2, 40), verbose=1)\n"
      ],
      "metadata": {
        "id": "6TuSGidDPQFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize and compile\n",
        "Initializing to my weights and biases account with the key: \"16894d54870c080a5b32b6c1fe211f8a09a38545\"\n",
        "This will save the intermediate results to a graph in weights and biases.\n",
        "\n",
        "Also need to do Wandb.finish() after to stop this run, otherwise it will just keep going at \"epoch 0\" on the same run."
      ],
      "metadata": {
        "id": "K3bS2LI7VZKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Automatically logs training metrics and hyperparameters\n",
        "#!pip install wandb\n",
        "import wandb\n",
        "from wandb.integration.keras import WandbCallback\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "\n",
        "wandb.init(project=\"Airplane-track\")\n",
        "wandb_callback = WandbCallback(save_graph=False, save_model=False)\n",
        "print(wandb.run.name)\n",
        "optimizer = Nadam(learning_rate=4.5e-3, clipnorm=1.0)\n",
        "#Compile the model\n",
        "small_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\",\n",
        "             #\"precision\",\n",
        "             #\"recall\"\n",
        "             ],\n",
        ")"
      ],
      "metadata": {
        "id": "GDrBRZSIgEQu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "b2e6e5c4-c672-401a-fcc2-393d6cc721f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m599002\u001b[0m (\u001b[33m599002-h-gskulen-p-vestlandet\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250401_065154-om3cr4tp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/599002-h-gskulen-p-vestlandet/Airplane-track/runs/om3cr4tp' target=\"_blank\">trim-disco-82</a></strong> to <a href='https://wandb.ai/599002-h-gskulen-p-vestlandet/Airplane-track' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/599002-h-gskulen-p-vestlandet/Airplane-track' target=\"_blank\">https://wandb.ai/599002-h-gskulen-p-vestlandet/Airplane-track</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/599002-h-gskulen-p-vestlandet/Airplane-track/runs/om3cr4tp' target=\"_blank\">https://wandb.ai/599002-h-gskulen-p-vestlandet/Airplane-track/runs/om3cr4tp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WandbCallback is deprecated and will be removed in a future release. Please use the WandbMetricsLogger, WandbModelCheckpoint, and WandbEvalCallback callbacks instead. See https://docs.wandb.ai/guides/integrations/keras for more information.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trim-disco-82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extra compiler in case i do not need to run all the code over again."
      ],
      "metadata": {
        "id": "n9h8k_7jV4yP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\",\n",
        "             #\"precision\",\n",
        "             #\"recall\"\n",
        "             ],\n",
        ")"
      ],
      "metadata": {
        "id": "l0VRQv249O1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This saves the model to the runtime memory. This means that when we do 'wandb.save(wandb.run.name + \"keras\") later, it uploads the best model to wandb storage that can be gathered later"
      ],
      "metadata": {
        "id": "J9ZvYiYaWEYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    wandb.run.name + \".keras\",\n",
        "    monitor='val_accuracy',  # monitor validation loss or any desired metric\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='max'  # 'min' for metrics like loss, 'max' for accuracy\n",
        ")"
      ],
      "metadata": {
        "id": "RwkBLY4QtqGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and logging\n",
        "This trains the model, plots the results, logs them to wandb, evaluates the model on the test data and finishes the run."
      ],
      "metadata": {
        "id": "p2l93TUlWRYI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normal errors\n",
        "### ResourceExhaustionError\n",
        "Self-explainatory. Lower Batch-size, number of base filters, number of base depth, simplify in some way.\n",
        "### Shape mismatch / tensor mismatch\n",
        "I have gotten this when adding new layers and when changing number of filters. The model passes the output channel number dynamically so that should be fine. When i have changed the number of filters, sometimes i have probably inserted an uncompatible number. just try to make it an even number and it is probably fine.\n",
        "### NotImplementedError: numpy() is only available when eager execution is enabled\n",
        "Usually happens when the .fit() crashes and you try to run it again. I think it then reinitializes with an old tensorflow version or something?\n",
        "You can either:\n",
        "\n",
        "\n",
        "*   run the code: \"tf.keras.backend.clear_session()\"\n",
        "*   then if that doesnt work: \"tf.compact.v1.enable_eager_execution()\"\n",
        "Again, that is a tf 1 thing, but yeah\n",
        "last but not least:\n",
        "* restart runtime\n",
        "\n",
        "That often fixes the problem if you cant find any other reason.\n",
        "\n"
      ],
      "metadata": {
        "id": "kGk54ho8B_KR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = small_model.fit(\n",
        "    train_airplane,\n",
        "    epochs=150,\n",
        "    validation_data=val_airplane,\n",
        "    callbacks=[\n",
        "        #early_stopping,\n",
        "        lr_scheduler,\n",
        "        checkpoint,\n",
        "        wandb_callback],\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Retrieve training history\n",
        "accuracy = history.history[\"accuracy\"]\n",
        "val_accuracy = history.history[\"val_accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "learning_rate = history.history[\"learning_rate\"]\n",
        "\n",
        "# Plot accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, accuracy, \"bo-\", label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_accuracy, \"ro-\", label=\"Validation Accuracy\")\n",
        "plt.title(\"Training & Validation Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, loss, \"bo-\", label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss, \"ro-\", label=\"Validation Loss\")\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Plot loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(epochs, learning_rate, \"bo-\", label=\"Learning rate\")\n",
        "plt.title(\"Learning rate\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Lr\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "wandb.log({\n",
        "    \"Final Training Accuracy\": history.history[\"accuracy\"][-1],\n",
        "    \"Final Validation Accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "    \"Final Training Loss\": history.history[\"loss\"][-1],\n",
        "    \"Final Validation Loss\": history.history[\"val_loss\"][-1],\n",
        "})\n",
        "\n",
        "test_loss, test_accuracy = small_model.evaluate(test_airplane)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "wandb.log({\n",
        "    \"Test Accuracy\": test_accuracy,\n",
        "    \"Test Loss\": test_loss,\n",
        "})\n",
        "wandb.save(wandb.run.name + \".keras\")\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tXPA-EXgqco",
        "outputId": "12ce6ea5-6ec1-4ccf-9e18-bffeff9db7fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.00044999999227002263.\n",
            "Epoch 1/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.0099 - loss: 4.9314\n",
            "Epoch 1: val_accuracy improved from -inf to 0.01027, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 412ms/step - accuracy: 0.0100 - loss: 4.9310 - val_accuracy: 0.0103 - val_loss: 4.8294 - learning_rate: 4.5000e-04\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.00044995066127739847.\n",
            "Epoch 2/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.0245 - loss: 4.7719\n",
            "Epoch 2: val_accuracy did not improve from 0.01027\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 383ms/step - accuracy: 0.0245 - loss: 4.7718 - val_accuracy: 0.0100 - val_loss: 4.8240 - learning_rate: 4.4995e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.000449802668299526.\n",
            "Epoch 3/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.0328 - loss: 4.6341\n",
            "Epoch 3: val_accuracy did not improve from 0.01027\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 383ms/step - accuracy: 0.0329 - loss: 4.6337 - val_accuracy: 0.0100 - val_loss: 4.8485 - learning_rate: 4.4980e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.00044955610064789653.\n",
            "Epoch 4/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.0534 - loss: 4.3892\n",
            "Epoch 4: val_accuracy improved from 0.01027 to 0.01117, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 386ms/step - accuracy: 0.0534 - loss: 4.3889 - val_accuracy: 0.0112 - val_loss: 4.8046 - learning_rate: 4.4956e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.00044921107473783195.\n",
            "Epoch 5/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.0736 - loss: 4.2045\n",
            "Epoch 5: val_accuracy improved from 0.01117 to 0.03231, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 387ms/step - accuracy: 0.0736 - loss: 4.2043 - val_accuracy: 0.0323 - val_loss: 4.5328 - learning_rate: 4.4921e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0004487676778808236.\n",
            "Epoch 6/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.0748 - loss: 4.0262\n",
            "Epoch 6: val_accuracy improved from 0.03231 to 0.09058, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 387ms/step - accuracy: 0.0749 - loss: 4.0261 - val_accuracy: 0.0906 - val_loss: 3.8518 - learning_rate: 4.4877e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0004482262011151761.\n",
            "Epoch 7/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.1199 - loss: 3.8948\n",
            "Epoch 7: val_accuracy improved from 0.09058 to 0.13919, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 386ms/step - accuracy: 0.1199 - loss: 3.8944 - val_accuracy: 0.1392 - val_loss: 3.6011 - learning_rate: 4.4823e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0004475868190638721.\n",
            "Epoch 8/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.1245 - loss: 3.7760\n",
            "Epoch 8: val_accuracy improved from 0.13919 to 0.14070, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 386ms/step - accuracy: 0.1245 - loss: 3.7759 - val_accuracy: 0.1407 - val_loss: 3.6040 - learning_rate: 4.4759e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0004468497936613858.\n",
            "Epoch 9/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.1602 - loss: 3.5797\n",
            "Epoch 9: val_accuracy did not improve from 0.14070\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.1601 - loss: 3.5798 - val_accuracy: 0.1205 - val_loss: 3.6192 - learning_rate: 4.4685e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.00044601550325751305.\n",
            "Epoch 10/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.1614 - loss: 3.5787\n",
            "Epoch 10: val_accuracy improved from 0.14070 to 0.16878, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 386ms/step - accuracy: 0.1614 - loss: 3.5786 - val_accuracy: 0.1688 - val_loss: 3.4472 - learning_rate: 4.4602e-04\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.0004450842970982194.\n",
            "Epoch 11/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.2055 - loss: 3.4024\n",
            "Epoch 11: val_accuracy did not improve from 0.16878\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 383ms/step - accuracy: 0.2055 - loss: 3.4025 - val_accuracy: 0.1597 - val_loss: 3.6208 - learning_rate: 4.4508e-04\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0004440565826371312.\n",
            "Epoch 12/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.2150 - loss: 3.3354\n",
            "Epoch 12: val_accuracy improved from 0.16878 to 0.20954, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 386ms/step - accuracy: 0.2150 - loss: 3.3353 - val_accuracy: 0.2095 - val_loss: 3.2379 - learning_rate: 4.4406e-04\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0004429327673278749.\n",
            "Epoch 13/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.2422 - loss: 3.2229\n",
            "Epoch 13: val_accuracy did not improve from 0.20954\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.2421 - loss: 3.2228 - val_accuracy: 0.2074 - val_loss: 3.2475 - learning_rate: 4.4293e-04\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0004417134041432291.\n",
            "Epoch 14/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.2809 - loss: 3.0990\n",
            "Epoch 14: val_accuracy improved from 0.20954 to 0.25151, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 386ms/step - accuracy: 0.2808 - loss: 3.0992 - val_accuracy: 0.2515 - val_loss: 3.0739 - learning_rate: 4.4171e-04\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0004403990169521421.\n",
            "Epoch 15/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.2563 - loss: 3.0923\n",
            "Epoch 15: val_accuracy did not improve from 0.25151\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.2564 - loss: 3.0922 - val_accuracy: 0.2228 - val_loss: 3.1447 - learning_rate: 4.4040e-04\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.00043899015872739255.\n",
            "Epoch 16/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.3273 - loss: 2.9580\n",
            "Epoch 16: val_accuracy did not improve from 0.25151\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.3272 - loss: 2.9583 - val_accuracy: 0.2412 - val_loss: 3.0693 - learning_rate: 4.3899e-04\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.00043748744064942.\n",
            "Epoch 17/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.3119 - loss: 2.9127\n",
            "Epoch 17: val_accuracy did not improve from 0.25151\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.3118 - loss: 2.9129 - val_accuracy: 0.1730 - val_loss: 3.5464 - learning_rate: 4.3749e-04\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.00043589159031398594.\n",
            "Epoch 18/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.3129 - loss: 2.9537\n",
            "Epoch 18: val_accuracy did not improve from 0.25151\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.3129 - loss: 2.9533 - val_accuracy: 0.2367 - val_loss: 3.0823 - learning_rate: 4.3589e-04\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.00043420318979769945.\n",
            "Epoch 19/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.3349 - loss: 2.7637\n",
            "Epoch 19: val_accuracy did not improve from 0.25151\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.3348 - loss: 2.7641 - val_accuracy: 0.2476 - val_loss: 3.1192 - learning_rate: 4.3420e-04\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.0004324230831116438.\n",
            "Epoch 20/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.3600 - loss: 2.7309\n",
            "Epoch 20: val_accuracy improved from 0.25151 to 0.27415, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 386ms/step - accuracy: 0.3598 - loss: 2.7311 - val_accuracy: 0.2742 - val_loss: 2.9611 - learning_rate: 4.3242e-04\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.0004305520560592413.\n",
            "Epoch 21/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.3702 - loss: 2.7591\n",
            "Epoch 21: val_accuracy did not improve from 0.27415\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.3701 - loss: 2.7591 - val_accuracy: 0.2739 - val_loss: 3.0442 - learning_rate: 4.3055e-04\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.00042859086534008384.\n",
            "Epoch 22/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.3811 - loss: 2.6237\n",
            "Epoch 22: val_accuracy did not improve from 0.27415\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.3811 - loss: 2.6240 - val_accuracy: 0.2693 - val_loss: 3.0257 - learning_rate: 4.2859e-04\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.00042654035496525466.\n",
            "Epoch 23/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.4110 - loss: 2.5417\n",
            "Epoch 23: val_accuracy improved from 0.27415 to 0.31250, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 386ms/step - accuracy: 0.4109 - loss: 2.5422 - val_accuracy: 0.3125 - val_loss: 2.7087 - learning_rate: 4.2654e-04\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.00042440148536115885.\n",
            "Epoch 24/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.4275 - loss: 2.4727\n",
            "Epoch 24: val_accuracy did not improve from 0.31250\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.4275 - loss: 2.4726 - val_accuracy: 0.2705 - val_loss: 3.0690 - learning_rate: 4.2440e-04\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.000422175187850371.\n",
            "Epoch 25/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.4297 - loss: 2.4389\n",
            "Epoch 25: val_accuracy did not improve from 0.31250\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.4296 - loss: 2.4392 - val_accuracy: 0.2862 - val_loss: 2.9493 - learning_rate: 4.2218e-04\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.0004198624228592962.\n",
            "Epoch 26/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.4433 - loss: 2.4300\n",
            "Epoch 26: val_accuracy did not improve from 0.31250\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.4433 - loss: 2.4300 - val_accuracy: 0.2835 - val_loss: 2.8744 - learning_rate: 4.1986e-04\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.00041746420902200043.\n",
            "Epoch 27/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.4737 - loss: 2.2891\n",
            "Epoch 27: val_accuracy improved from 0.31250 to 0.31914, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 387ms/step - accuracy: 0.4736 - loss: 2.2896 - val_accuracy: 0.3191 - val_loss: 2.8767 - learning_rate: 4.1746e-04\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.0004149815649725497.\n",
            "Epoch 28/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.4834 - loss: 2.2604\n",
            "Epoch 28: val_accuracy improved from 0.31914 to 0.33243, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 387ms/step - accuracy: 0.4834 - loss: 2.2607 - val_accuracy: 0.3324 - val_loss: 2.6309 - learning_rate: 4.1498e-04\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.00041241562576033175.\n",
            "Epoch 29/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.5161 - loss: 2.1367\n",
            "Epoch 29: val_accuracy did not improve from 0.33243\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.5159 - loss: 2.1374 - val_accuracy: 0.2950 - val_loss: 3.0801 - learning_rate: 4.1242e-04\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.00040976752643473446.\n",
            "Epoch 30/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.5323 - loss: 2.1128\n",
            "Epoch 30: val_accuracy improved from 0.33243 to 0.34994, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 386ms/step - accuracy: 0.5322 - loss: 2.1132 - val_accuracy: 0.3499 - val_loss: 2.7118 - learning_rate: 4.0977e-04\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.0004070383438374847.\n",
            "Epoch 31/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.5225 - loss: 2.1674\n",
            "Epoch 31: val_accuracy did not improve from 0.34994\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 383ms/step - accuracy: 0.5225 - loss: 2.1674 - val_accuracy: 0.3433 - val_loss: 2.7599 - learning_rate: 4.0704e-04\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.0004042294167447835.\n",
            "Epoch 32/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.5425 - loss: 2.0817\n",
            "Epoch 32: val_accuracy did not improve from 0.34994\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.5424 - loss: 2.0819 - val_accuracy: 0.3200 - val_loss: 3.0629 - learning_rate: 4.0423e-04\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.00040134185110218823.\n",
            "Epoch 33/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.5505 - loss: 2.0199\n",
            "Epoch 33: val_accuracy improved from 0.34994 to 0.35115, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 387ms/step - accuracy: 0.5504 - loss: 2.0200 - val_accuracy: 0.3511 - val_loss: 2.7663 - learning_rate: 4.0134e-04\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.0003983769565820694.\n",
            "Epoch 34/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.5596 - loss: 1.9995\n",
            "Epoch 34: val_accuracy did not improve from 0.35115\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.5596 - loss: 1.9995 - val_accuracy: 0.3379 - val_loss: 2.8876 - learning_rate: 3.9838e-04\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.0003953360428567976.\n",
            "Epoch 35/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.5688 - loss: 1.9996\n",
            "Epoch 35: val_accuracy improved from 0.35115 to 0.36171, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 387ms/step - accuracy: 0.5687 - loss: 1.9996 - val_accuracy: 0.3617 - val_loss: 2.7458 - learning_rate: 3.9534e-04\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.00039222039049491286.\n",
            "Epoch 36/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.5985 - loss: 1.9037\n",
            "Epoch 36: val_accuracy did not improve from 0.36171\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.5984 - loss: 1.9038 - val_accuracy: 0.3264 - val_loss: 2.9348 - learning_rate: 3.9222e-04\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.00038903148379176855.\n",
            "Epoch 37/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.5992 - loss: 1.8927\n",
            "Epoch 37: val_accuracy improved from 0.36171 to 0.36624, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 386ms/step - accuracy: 0.5992 - loss: 1.8927 - val_accuracy: 0.3662 - val_loss: 2.7032 - learning_rate: 3.8903e-04\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.0003857706324197352.\n",
            "Epoch 38/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6087 - loss: 1.8851\n",
            "Epoch 38: val_accuracy improved from 0.36624 to 0.37621, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 386ms/step - accuracy: 0.6086 - loss: 1.8850 - val_accuracy: 0.3762 - val_loss: 2.7237 - learning_rate: 3.8577e-04\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.00038243926246650517.\n",
            "Epoch 39/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6081 - loss: 1.9012\n",
            "Epoch 39: val_accuracy did not improve from 0.37621\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 383ms/step - accuracy: 0.6082 - loss: 1.9010 - val_accuracy: 0.3448 - val_loss: 2.8845 - learning_rate: 3.8244e-04\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.00037903888733126223.\n",
            "Epoch 40/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6077 - loss: 1.8764\n",
            "Epoch 40: val_accuracy did not improve from 0.37621\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6077 - loss: 1.8761 - val_accuracy: 0.3276 - val_loss: 2.9797 - learning_rate: 3.7904e-04\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.0003755709039978683.\n",
            "Epoch 41/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6521 - loss: 1.7139\n",
            "Epoch 41: val_accuracy did not improve from 0.37621\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6519 - loss: 1.7143 - val_accuracy: 0.3339 - val_loss: 3.1663 - learning_rate: 3.7557e-04\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.0003720369713846594.\n",
            "Epoch 42/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6423 - loss: 1.7594\n",
            "Epoch 42: val_accuracy did not improve from 0.37621\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6423 - loss: 1.7597 - val_accuracy: 0.3433 - val_loss: 3.2278 - learning_rate: 3.7204e-04\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.00036843851557932794.\n",
            "Epoch 43/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6351 - loss: 1.7917\n",
            "Epoch 43: val_accuracy did not improve from 0.37621\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6351 - loss: 1.7913 - val_accuracy: 0.3327 - val_loss: 3.0148 - learning_rate: 3.6844e-04\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.00036477719550020993.\n",
            "Epoch 44/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6783 - loss: 1.6225\n",
            "Epoch 44: val_accuracy did not improve from 0.37621\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6782 - loss: 1.6230 - val_accuracy: 0.3684 - val_loss: 2.7843 - learning_rate: 3.6478e-04\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.0003610545536503196.\n",
            "Epoch 45/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6907 - loss: 1.6120\n",
            "Epoch 45: val_accuracy did not improve from 0.37621\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6906 - loss: 1.6123 - val_accuracy: 0.3388 - val_loss: 3.0703 - learning_rate: 3.6105e-04\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.0003572722780518234.\n",
            "Epoch 46/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6485 - loss: 1.7213\n",
            "Epoch 46: val_accuracy did not improve from 0.37621\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6485 - loss: 1.7212 - val_accuracy: 0.3297 - val_loss: 3.1334 - learning_rate: 3.5727e-04\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.0003534319985192269.\n",
            "Epoch 47/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6741 - loss: 1.6504\n",
            "Epoch 47: val_accuracy did not improve from 0.37621\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6741 - loss: 1.6502 - val_accuracy: 0.3524 - val_loss: 2.9718 - learning_rate: 3.5343e-04\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.00034953540307469666.\n",
            "Epoch 48/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6795 - loss: 1.6318\n",
            "Epoch 48: val_accuracy did not improve from 0.37621\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6795 - loss: 1.6320 - val_accuracy: 0.3545 - val_loss: 3.0372 - learning_rate: 3.4954e-04\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.0003455842088442296.\n",
            "Epoch 49/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6740 - loss: 1.6276\n",
            "Epoch 49: val_accuracy did not improve from 0.37621\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6740 - loss: 1.6279 - val_accuracy: 0.3194 - val_loss: 3.2672 - learning_rate: 3.4558e-04\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.0003415801911614835.\n",
            "Epoch 50/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6806 - loss: 1.6388\n",
            "Epoch 50: val_accuracy did not improve from 0.37621\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6807 - loss: 1.6386 - val_accuracy: 0.2911 - val_loss: 3.6531 - learning_rate: 3.4158e-04\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 0.0003375249798409641.\n",
            "Epoch 51/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6729 - loss: 1.6493\n",
            "Epoch 51: val_accuracy did not improve from 0.37621\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6730 - loss: 1.6491 - val_accuracy: 0.3354 - val_loss: 3.4019 - learning_rate: 3.3752e-04\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 0.0003334204957354814.\n",
            "Epoch 52/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6829 - loss: 1.6128\n",
            "Epoch 52: val_accuracy improved from 0.37621 to 0.38104, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 387ms/step - accuracy: 0.6829 - loss: 1.6129 - val_accuracy: 0.3810 - val_loss: 2.9796 - learning_rate: 3.3342e-04\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 0.0003292684559710324.\n",
            "Epoch 53/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6885 - loss: 1.6146\n",
            "Epoch 53: val_accuracy did not improve from 0.38104\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6884 - loss: 1.6147 - val_accuracy: 0.3487 - val_loss: 3.1794 - learning_rate: 3.2927e-04\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 0.0003250706649851054.\n",
            "Epoch 54/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6858 - loss: 1.5564\n",
            "Epoch 54: val_accuracy did not improve from 0.38104\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6857 - loss: 1.5569 - val_accuracy: 0.3418 - val_loss: 3.2770 - learning_rate: 3.2507e-04\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 0.00032082904363051057.\n",
            "Epoch 55/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7107 - loss: 1.5028\n",
            "Epoch 55: val_accuracy did not improve from 0.38104\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7106 - loss: 1.5031 - val_accuracy: 0.3400 - val_loss: 3.4065 - learning_rate: 3.2083e-04\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 0.0003165453963447362.\n",
            "Epoch 56/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6762 - loss: 1.6437\n",
            "Epoch 56: val_accuracy did not improve from 0.38104\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6763 - loss: 1.6432 - val_accuracy: 0.3665 - val_loss: 3.0769 - learning_rate: 3.1655e-04\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 0.0003122216439805925.\n",
            "Epoch 57/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7087 - loss: 1.5104\n",
            "Epoch 57: val_accuracy improved from 0.38104 to 0.40187, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 387ms/step - accuracy: 0.7087 - loss: 1.5104 - val_accuracy: 0.4019 - val_loss: 3.0133 - learning_rate: 3.1222e-04\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 0.0003078595909755677.\n",
            "Epoch 58/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7006 - loss: 1.5373\n",
            "Epoch 58: val_accuracy did not improve from 0.40187\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7005 - loss: 1.5377 - val_accuracy: 0.3478 - val_loss: 3.2838 - learning_rate: 3.0786e-04\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 0.0003034612745977938.\n",
            "Epoch 59/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6924 - loss: 1.5820\n",
            "Epoch 59: val_accuracy did not improve from 0.40187\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6924 - loss: 1.5821 - val_accuracy: 0.3481 - val_loss: 3.3361 - learning_rate: 3.0346e-04\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 0.0002990285574924201.\n",
            "Epoch 60/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6888 - loss: 1.5977\n",
            "Epoch 60: val_accuracy did not improve from 0.40187\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6888 - loss: 1.5975 - val_accuracy: 0.3433 - val_loss: 3.1721 - learning_rate: 2.9903e-04\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 0.0002945633605122566.\n",
            "Epoch 61/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7113 - loss: 1.5056\n",
            "Epoch 61: val_accuracy did not improve from 0.40187\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7114 - loss: 1.5055 - val_accuracy: 0.3762 - val_loss: 2.9921 - learning_rate: 2.9456e-04\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 0.0002900677209254354.\n",
            "Epoch 62/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6976 - loss: 1.5492\n",
            "Epoch 62: val_accuracy did not improve from 0.40187\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6976 - loss: 1.5492 - val_accuracy: 0.3910 - val_loss: 3.0078 - learning_rate: 2.9007e-04\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 0.0002855435013771057.\n",
            "Epoch 63/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7062 - loss: 1.5030\n",
            "Epoch 63: val_accuracy did not improve from 0.40187\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7063 - loss: 1.5027 - val_accuracy: 0.3889 - val_loss: 2.9460 - learning_rate: 2.8554e-04\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 0.00028099282644689083.\n",
            "Epoch 64/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7041 - loss: 1.5196\n",
            "Epoch 64: val_accuracy did not improve from 0.40187\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7042 - loss: 1.5193 - val_accuracy: 0.3502 - val_loss: 3.2287 - learning_rate: 2.8099e-04\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 0.00027641752967610955.\n",
            "Epoch 65/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7263 - loss: 1.4371\n",
            "Epoch 65: val_accuracy did not improve from 0.40187\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7263 - loss: 1.4374 - val_accuracy: 0.3608 - val_loss: 3.2657 - learning_rate: 2.7642e-04\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 0.00027181970654055476.\n",
            "Epoch 66/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7231 - loss: 1.4452\n",
            "Epoch 66: val_accuracy improved from 0.40187 to 0.41999, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 386ms/step - accuracy: 0.7231 - loss: 1.4452 - val_accuracy: 0.4200 - val_loss: 2.7243 - learning_rate: 2.7182e-04\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 0.00026720145251601934.\n",
            "Epoch 67/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.7033 - loss: 1.5058\n",
            "Epoch 67: val_accuracy did not improve from 0.41999\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7033 - loss: 1.5059 - val_accuracy: 0.3590 - val_loss: 3.3640 - learning_rate: 2.6720e-04\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 0.00026256463024765253.\n",
            "Epoch 68/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6892 - loss: 1.5903\n",
            "Epoch 68: val_accuracy did not improve from 0.41999\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6892 - loss: 1.5899 - val_accuracy: 0.3877 - val_loss: 3.1187 - learning_rate: 2.6256e-04\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 0.0002579113934189081.\n",
            "Epoch 69/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6902 - loss: 1.5632\n",
            "Epoch 69: val_accuracy did not improve from 0.41999\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6902 - loss: 1.5632 - val_accuracy: 0.3931 - val_loss: 2.8787 - learning_rate: 2.5791e-04\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 0.0002532436919864267.\n",
            "Epoch 70/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7044 - loss: 1.5108\n",
            "Epoch 70: val_accuracy did not improve from 0.41999\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7045 - loss: 1.5105 - val_accuracy: 0.3986 - val_loss: 3.0424 - learning_rate: 2.5324e-04\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 0.0002485636796336621.\n",
            "Epoch 71/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7171 - loss: 1.4615\n",
            "Epoch 71: val_accuracy did not improve from 0.41999\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7171 - loss: 1.4618 - val_accuracy: 0.3690 - val_loss: 3.1410 - learning_rate: 2.4856e-04\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 0.00024387333542108536.\n",
            "Epoch 72/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7159 - loss: 1.4719\n",
            "Epoch 72: val_accuracy did not improve from 0.41999\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7159 - loss: 1.4718 - val_accuracy: 0.3949 - val_loss: 2.8788 - learning_rate: 2.4387e-04\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 0.0002391747257206589.\n",
            "Epoch 73/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7111 - loss: 1.4728\n",
            "Epoch 73: val_accuracy did not improve from 0.41999\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7109 - loss: 1.4733 - val_accuracy: 0.3889 - val_loss: 2.9677 - learning_rate: 2.3917e-04\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 0.0002344699460081756.\n",
            "Epoch 74/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7088 - loss: 1.4950\n",
            "Epoch 74: val_accuracy did not improve from 0.41999\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7088 - loss: 1.4949 - val_accuracy: 0.3841 - val_loss: 3.0273 - learning_rate: 2.3447e-04\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 0.000229761004447937.\n",
            "Epoch 75/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7048 - loss: 1.5181\n",
            "Epoch 75: val_accuracy improved from 0.41999 to 0.42572, saving model to trim-disco-82.keras\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 386ms/step - accuracy: 0.7048 - loss: 1.5183 - val_accuracy: 0.4257 - val_loss: 2.7844 - learning_rate: 2.2976e-04\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 0.00022504998196382076.\n",
            "Epoch 76/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7290 - loss: 1.3998\n",
            "Epoch 76: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7289 - loss: 1.4000 - val_accuracy: 0.3961 - val_loss: 2.9989 - learning_rate: 2.2505e-04\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 0.00022033900313545018.\n",
            "Epoch 77/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7182 - loss: 1.4499\n",
            "Epoch 77: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7182 - loss: 1.4497 - val_accuracy: 0.3892 - val_loss: 3.0602 - learning_rate: 2.2034e-04\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 0.00021563006157521158.\n",
            "Epoch 78/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7049 - loss: 1.5277\n",
            "Epoch 78: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7050 - loss: 1.5273 - val_accuracy: 0.3992 - val_loss: 2.9497 - learning_rate: 2.1563e-04\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 0.0002109252818627283.\n",
            "Epoch 79/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7276 - loss: 1.4038\n",
            "Epoch 79: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7276 - loss: 1.4038 - val_accuracy: 0.3720 - val_loss: 3.2713 - learning_rate: 2.1093e-04\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 0.00020622667216230184.\n",
            "Epoch 80/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7159 - loss: 1.4465\n",
            "Epoch 80: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7160 - loss: 1.4463 - val_accuracy: 0.4091 - val_loss: 2.8748 - learning_rate: 2.0623e-04\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 0.00020153631339780986.\n",
            "Epoch 81/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7235 - loss: 1.4124\n",
            "Epoch 81: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7234 - loss: 1.4126 - val_accuracy: 0.3970 - val_loss: 2.9729 - learning_rate: 2.0154e-04\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 0.00019685630104504526.\n",
            "Epoch 82/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7042 - loss: 1.5038\n",
            "Epoch 82: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7042 - loss: 1.5037 - val_accuracy: 0.3871 - val_loss: 3.1533 - learning_rate: 1.9686e-04\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 0.00019218861416447908.\n",
            "Epoch 83/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6984 - loss: 1.5239\n",
            "Epoch 83: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6985 - loss: 1.5236 - val_accuracy: 0.4007 - val_loss: 3.0025 - learning_rate: 1.9219e-04\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 0.0001875353918876499.\n",
            "Epoch 84/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7133 - loss: 1.4640\n",
            "Epoch 84: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7133 - loss: 1.4636 - val_accuracy: 0.3958 - val_loss: 2.9949 - learning_rate: 1.8754e-04\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 0.00018289856961928308.\n",
            "Epoch 85/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7180 - loss: 1.4371\n",
            "Epoch 85: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7179 - loss: 1.4374 - val_accuracy: 0.4079 - val_loss: 2.9441 - learning_rate: 1.8290e-04\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 0.00017828025738708675.\n",
            "Epoch 86/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6979 - loss: 1.5320\n",
            "Epoch 86: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.6980 - loss: 1.5316 - val_accuracy: 0.3877 - val_loss: 3.0227 - learning_rate: 1.7828e-04\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 0.00017368246335536242.\n",
            "Epoch 87/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7141 - loss: 1.4520\n",
            "Epoch 87: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7140 - loss: 1.4522 - val_accuracy: 0.3970 - val_loss: 2.9546 - learning_rate: 1.7368e-04\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 0.00016910721024032682.\n",
            "Epoch 88/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7152 - loss: 1.4526\n",
            "Epoch 88: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7153 - loss: 1.4524 - val_accuracy: 0.3961 - val_loss: 2.9251 - learning_rate: 1.6911e-04\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 0.00016455649165436625.\n",
            "Epoch 89/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7292 - loss: 1.3837\n",
            "Epoch 89: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7291 - loss: 1.3840 - val_accuracy: 0.3937 - val_loss: 3.0961 - learning_rate: 1.6456e-04\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 0.000160032301209867.\n",
            "Epoch 90/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7181 - loss: 1.4385\n",
            "Epoch 90: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7181 - loss: 1.4384 - val_accuracy: 0.3970 - val_loss: 3.0956 - learning_rate: 1.6003e-04\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 0.0001555366034153849.\n",
            "Epoch 91/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7191 - loss: 1.4387\n",
            "Epoch 91: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7191 - loss: 1.4386 - val_accuracy: 0.3789 - val_loss: 3.1050 - learning_rate: 1.5554e-04\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 0.00015107145009096712.\n",
            "Epoch 92/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7243 - loss: 1.4055\n",
            "Epoch 92: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7243 - loss: 1.4055 - val_accuracy: 0.3829 - val_loss: 3.2377 - learning_rate: 1.5107e-04\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 0.00014663870388176292.\n",
            "Epoch 93/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7228 - loss: 1.3950\n",
            "Epoch 93: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7228 - loss: 1.3950 - val_accuracy: 0.4034 - val_loss: 2.9460 - learning_rate: 1.4664e-04\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 0.00014224040205590427.\n",
            "Epoch 94/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7153 - loss: 1.4337\n",
            "Epoch 94: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7153 - loss: 1.4338 - val_accuracy: 0.3925 - val_loss: 3.0302 - learning_rate: 1.4224e-04\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 0.00013787837815470994.\n",
            "Epoch 95/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7150 - loss: 1.4349\n",
            "Epoch 95: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7150 - loss: 1.4352 - val_accuracy: 0.4091 - val_loss: 2.9379 - learning_rate: 1.3788e-04\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 0.00013355458213482052.\n",
            "Epoch 96/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7335 - loss: 1.3644\n",
            "Epoch 96: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7334 - loss: 1.3648 - val_accuracy: 0.4037 - val_loss: 3.0098 - learning_rate: 1.3355e-04\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 0.00012927093484904617.\n",
            "Epoch 97/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7190 - loss: 1.4252\n",
            "Epoch 97: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7190 - loss: 1.4254 - val_accuracy: 0.4182 - val_loss: 2.8324 - learning_rate: 1.2927e-04\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 0.00012502932804636657.\n",
            "Epoch 98/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7208 - loss: 1.4235\n",
            "Epoch 98: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7207 - loss: 1.4238 - val_accuracy: 0.4046 - val_loss: 3.0480 - learning_rate: 1.2503e-04\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 0.00012083156616427004.\n",
            "Epoch 99/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7242 - loss: 1.3948\n",
            "Epoch 99: val_accuracy did not improve from 0.42572\n",
            "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.7241 - loss: 1.3951 - val_accuracy: 0.4158 - val_loss: 2.8332 - learning_rate: 1.2083e-04\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 0.00011667952639982104.\n",
            "Epoch 100/150\n",
            "\u001b[1m 36/138\u001b[0m \u001b[32mâ”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m31s\u001b[0m 308ms/step - accuracy: 0.7286 - loss: 1.3418"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## extra code for logging\n",
        "not necessary to run"
      ],
      "metadata": {
        "id": "5sv0pmvsWraX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.log({\n",
        "    \"Final Training Accuracy\": history.history[\"accuracy\"][-1],\n",
        "    \"Final Validation Accuracy\": history.history[\"val_accuracy\"][-1],\n",
        "    \"Final Training Loss\": history.history[\"loss\"][-1],\n",
        "    \"Final Validation Loss\": history.history[\"val_loss\"][-1],\n",
        "})\n"
      ],
      "metadata": {
        "id": "cKwqv1Yptrdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = small_model.evaluate(new_test_dataset)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "wandb.log({\n",
        "    \"Test Accuracy\": test_accuracy,\n",
        "    \"Test Loss\": test_loss,\n",
        "})\n",
        "wandb.save(wandb.run.name + \".keras\")\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "ZjljGDvdthfV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        },
        "outputId": "ede8c10f-0e24-4bbf-906e-6c6abeecf572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7576 - loss: 0.6741\n",
            "Test Accuracy: 0.7747\n",
            "Test Loss: 0.6464\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Final Training Accuracy</td><td>â–</td></tr><tr><td>Final Training Loss</td><td>â–</td></tr><tr><td>Final Validation Accuracy</td><td>â–</td></tr><tr><td>Final Validation Loss</td><td>â–</td></tr><tr><td>Test Accuracy</td><td>â–</td></tr><tr><td>Test Loss</td><td>â–</td></tr><tr><td>accuracy</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–„â–„â–„â–„â–„â–…â–„â–…â–…â–…â–†â–…â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>learning_rate</td><td>â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–…â–…â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–</td></tr><tr><td>loss</td><td>â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–…â–…â–„â–„â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_accuracy</td><td>â–„â–„â–„â–„â–…â–ƒâ–ƒâ–‚â–â–†â–†â–‚â–…â–…â–…â–…â–„â–ƒâ–„â–…â–…â–„â–…â–„â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>val_loss</td><td>â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–â–â–â–‚â–‚â–â–‚â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Final Training Accuracy</td><td>0.63665</td></tr><tr><td>Final Training Loss</td><td>0.92914</td></tr><tr><td>Final Validation Accuracy</td><td>0.7587</td></tr><tr><td>Final Validation Loss</td><td>0.68665</td></tr><tr><td>Test Accuracy</td><td>0.77471</td></tr><tr><td>Test Loss</td><td>0.64635</td></tr><tr><td>accuracy</td><td>0.63665</td></tr><tr><td>best_epoch</td><td>85</td></tr><tr><td>best_val_loss</td><td>0.66972</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>loss</td><td>0.92914</td></tr><tr><td>val_accuracy</td><td>0.7587</td></tr><tr><td>val_loss</td><td>0.68665</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">polar-dew-41</strong> at: <a href='https://wandb.ai/599002-h-gskulen-p-vestlandet/Airplane-track/runs/0fqe5xw7' target=\"_blank\">https://wandb.ai/599002-h-gskulen-p-vestlandet/Airplane-track/runs/0fqe5xw7</a><br> View project at: <a href='https://wandb.ai/599002-h-gskulen-p-vestlandet/Airplane-track' target=\"_blank\">https://wandb.ai/599002-h-gskulen-p-vestlandet/Airplane-track</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250317_153606-0fqe5xw7/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"GoodOne.keras\")"
      ],
      "metadata": {
        "id": "haNDuTUKDY1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "GfxXmvLrkOMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full code\n",
        "outdated"
      ],
      "metadata": {
        "id": "ZQQQwNzVhYun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers, preprocessing\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!echo '{\"username\":\"vegardaaalbretsen\",\"key\":\"18f385007d1223dd35dc94f16e311545\"}' > ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d seryouxblaster764/fgvc-aircraft\n",
        "!unzip fgvc-aircraft.zip -d /content/dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "zQWm5PzrnLvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the path to the dataset\n",
        "dataset_path = '/content/dataset'\n",
        "image_path = '/content/dataset/fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images'\n",
        "\n",
        "# Load CSV files\n",
        "train_df = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\n",
        "val_df = pd.read_csv(os.path.join(dataset_path, 'val.csv'))\n",
        "test_df = pd.read_csv(os.path.join(dataset_path, 'test.csv'))\n",
        "\n",
        "# Add full image paths to DataFrames\n",
        "train_df['filepath'] = train_df['filename'].apply(lambda x: os.path.join(image_path, x))\n",
        "val_df['filepath'] = val_df['filename'].apply(lambda x: os.path.join(image_path, x))\n",
        "test_df['filepath'] = test_df['filename'].apply(lambda x: os.path.join(image_path, x))\n",
        "\n",
        "# Convert class labels to categorical\n",
        "train_df['Labels'] = train_df['Labels'].astype(str)\n",
        "val_df['Labels'] = val_df['Labels'].astype(str)\n",
        "test_df['Labels'] = test_df['Labels'].astype(str)\n",
        "\n",
        "# Image and Batch size\n",
        "img_size = (224, 224)\n",
        "batch_size = 64\n",
        "\n",
        "# Function to load and preprocess images with augmentation for training\n",
        "def load_and_augment_image(image_path, label):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (224,224)) / 255.0  # Normalize\n",
        "\n",
        "    # Apply Data Augmentation\n",
        "    img = tf.image.random_flip_left_right(img)\n",
        "    img = tf.image.random_brightness(img, max_delta=0.10)\n",
        "    img = tf.image.random_contrast(img, lower=0.9, upper=1.10)\n",
        "    img = tf.image.random_saturation(img, lower=0.9, upper=1.10)\n",
        "    img = tf.image.random_hue(img, max_delta=0.02)\n",
        "\n",
        "    # **Additional Transformations**\n",
        "    #img = tf.image.random_crop(img, size=[200, 200, 3])  # âœ… Random Cropping (optional)\n",
        "    #img = tf.image.resize(img, (224, 224))  # Resize Back\n",
        "\n",
        "    return img, label\n",
        "\n",
        "# Function to load images without augmentation for validation/testing\n",
        "def load_image(image_path, label):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (224,224)) / 255.0  # Normalize\n",
        "    label = tf.reshape(label, [])\n",
        "    return img, label\n",
        "\n",
        "# Convert DataFrames to TensorFlow datasets\n",
        "def dataframe_to_dataset(df, batch_size=batch_size, shuffle=True, augment=False):\n",
        "    file_paths = df['filepath'].values\n",
        "    labels = df['Labels'].astype('category').cat.codes.values  # Convert labels to numerical format\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
        "\n",
        "    if augment:\n",
        "        dataset = dataset.map(lambda x, y: load_and_augment_image(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda x, y: load_image(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(len(df))\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(2)  # Ensure consistency\n",
        "    return dataset\n",
        "\n",
        "# Create datasets using tf.data pipeline with augmentation for training\n",
        "train_dataset = dataframe_to_dataset(train_df, batch_size=batch_size, augment=True)\n",
        "val_dataset = dataframe_to_dataset(val_df, batch_size=batch_size, shuffle=False, augment=False)\n",
        "test_dataset = dataframe_to_dataset(test_df, batch_size=batch_size, shuffle=False, augment=False)\n",
        "\n",
        "def relu6(x):\n",
        "    return tf.nn.relu6(x)\n",
        "\n",
        "def se_module(inputs, reduction=4):\n",
        "    input_channels = inputs.shape[-1]\n",
        "    reduced_channels = input_channels // reduction\n",
        "\n",
        "    se = layers.GlobalAveragePooling2D()(inputs)\n",
        "    se = layers.Reshape((1, 1, input_channels))(se)\n",
        "    se = layers.Dense(reduced_channels, activation='relu')(se)\n",
        "    se = layers.Dense(input_channels, activation='sigmoid')(se)\n",
        "    return layers.multiply([inputs, se])\n",
        "\n",
        "class StochasticDepth(tf.keras.layers.Layer):\n",
        "    def __init__(self, drop_prob=0.2, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        if training:\n",
        "            keep_prob = 1.0 - self.drop_prob\n",
        "            batch_size = tf.shape(inputs)[0]\n",
        "            random_tensor = keep_prob + tf.random.uniform([batch_size, 1, 1, 1], dtype=inputs.dtype)\n",
        "            binary_tensor = tf.floor(random_tensor)  # Convert to 0 or 1\n",
        "            return inputs * binary_tensor / keep_prob  # Scale for variance correction\n",
        "        return inputs\n",
        "\n",
        "def inverted_residual_block(inputs, expansion_factor, output_channels, stride, use_se=True, dropout_rate=0.1, drop_prob=0.2):\n",
        "    input_channels = inputs.shape[-1]\n",
        "    expanded_channels = input_channels * expansion_factor\n",
        "\n",
        "    # Expansion Phase\n",
        "    x = layers.Conv2D(expanded_channels, kernel_size=1, padding='same', use_bias=False)(inputs)\n",
        "    x = layers.Activation('relu6')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Depthwise Convolution\n",
        "    x = layers.DepthwiseConv2D(kernel_size=3, strides=stride, padding='same', use_bias=False)(x)\n",
        "    x = layers.Activation('relu6')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Dropout to reduce overfitting\n",
        "    x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Squeeze-and-Excitation Module (Optional)\n",
        "    if use_se:\n",
        "        x = se_module(x)\n",
        "\n",
        "    # Projection Phase\n",
        "    x = layers.Conv2D(output_channels, kernel_size=1, padding='same', use_bias=False, kernel_regularizer=l2(1e-4))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # âœ… Apply Stochastic Depth before residual connection\n",
        "    x = StochasticDepth(drop_prob=drop_prob)(x)\n",
        "\n",
        "    # Residual Connection\n",
        "    if stride == 1 and input_channels == output_channels:\n",
        "        x = layers.add([inputs, x])\n",
        "\n",
        "    return x\n",
        "\n",
        "def scale_parameters(base_depth, base_width, phi, alpha=1.2, beta=1.1, gamma=1.15):\n",
        "    depth = int(base_depth * alpha ** phi)\n",
        "    width = int(base_width * beta ** phi)\n",
        "    return depth, width\n",
        "\n",
        "def build_scaled_model(phi, input_shape=(224, 224, 3), num_classes=100):\n",
        "    base_depth = 3   # Number of IR blocks per stage\n",
        "    base_width = 112  # Initial number of filters\n",
        "    base_resolution = 224  # Default image size\n",
        "\n",
        "    depth, width = scale_parameters(base_depth, base_width, phi)\n",
        "\n",
        "    inputs = layers.Input(shape=(224,224,3))\n",
        "\n",
        "    # Initial Conv Layer\n",
        "    x = layers.Conv2D(width, kernel_size=3, strides=2, padding='same', use_bias=False)(inputs)\n",
        "    x = layers.Activation('relu6')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Stacking Inverted Residual Blocks with Scaling & Stochastic Depth\n",
        "    for i in range(depth):\n",
        "        stride = 1 if i > 0 else 2  # Stride 2 for first block in each stage\n",
        "        drop_prob = 0.05 + (0.02 * i)  # Increasing drop probability as depth increases\n",
        "        x = inverted_residual_block(x, expansion_factor=4, output_channels=width, stride=stride, use_se=True, drop_prob=drop_prob)\n",
        "        width *= 2  # Increase filters at each stage\n",
        "\n",
        "    # Final Global Pooling and Classifier\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "small_model = build_scaled_model(phi=0)  # Small\n",
        "\n",
        "def cosine_annealing(epoch, lr):\n",
        "    min_lr = 2e-5  # Raise this a bit (previously 1e-6)\n",
        "    max_lr = 0.005  # Slightly higher than before\n",
        "    T_max = 100  # Stretch over 100 epochs for slower decay\n",
        "\n",
        "    new_lr = min_lr + (max_lr - min_lr) * (1 + tf.math.cos(epoch / T_max * 3.141592653589793)) / 2\n",
        "    return float(new_lr)\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(cosine_annealing, verbose=1)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", patience=15, restore_best_weights=True\n",
        ")\n",
        "#Reduces Learning rate on plateau\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-6\n",
        ")\n",
        "# Saves the model during training\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"best_model.keras\", monitor=\"val_loss\", save_best_only=True)\n",
        "\n",
        "# Automatically logs training metrics and hyperparameters\n",
        "#!pip install wandb\n",
        "import wandb\n",
        "from wandb.integration.keras import WandbCallback\n",
        "wandb.init(project=\"Airplane-track\")\n",
        "wandb_callback = WandbCallback(save_graph=False, save_model=False)\n",
        "\n",
        "#Compile the model\n",
        "small_model.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(learning_rate=0.001, weight_decay=1e-4),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "collapsed": true,
        "id": "RiozQRYlhYWX",
        "outputId": "1684cfb8-f926-40e3-afbe-ad01b7343d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "{{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[3,3,3,59856518619] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node StatelessRandomUniformV2}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:StatelessRandomUniformV2] name: ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0fe3e067d165>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m \u001b[0msmall_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_scaled_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Small\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcosine_annealing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-0fe3e067d165>\u001b[0m in \u001b[0;36mbuild_scaled_model\u001b[0;34m(phi, input_shape, num_classes)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m# Initial Conv Layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu6'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/random.py\u001b[0m in \u001b[0;36muniform\u001b[0;34m(shape, minval, maxval, dtype, seed)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cast_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     return tf.random.stateless_uniform(\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[3,3,3,59856518619] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node StatelessRandomUniformV2}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:StatelessRandomUniformV2] name: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = small_model.fit(\n",
        "    train_dataset,\n",
        "    epochs=100,\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=[early_stopping, reduce_lr, lr_scheduler, checkpoint, wandb_callback],\n",
        ")"
      ],
      "metadata": {
        "id": "_rQ2ax_uirU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRAD CAM to analyze what the model sees"
      ],
      "metadata": {
        "id": "TjDjBOlQore-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Ensure the custom layer is registered\n",
        "keras.utils.get_custom_objects().update({\"StochasticDepth\": StochasticDepth})\n",
        "# Load your pre-trained model\n",
        "# This model has to be present in the runtime memory\n",
        "model = keras.models.load_model('dark-microwave-30.keras', custom_objects={'StochasticDepth': StochasticDepth})\n"
      ],
      "metadata": {
        "id": "8AgCuhbPo-SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identify the last convolutional layer, we need the output"
      ],
      "metadata": {
        "id": "outkT6MsqXB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the model architecture\n",
        "small_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NUGs8vjtqbZE",
        "outputId": "c0148452-66e4-4b50-8447-61fbe1d66b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ -                      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m112\u001b[0m)    â”‚          \u001b[38;5;34m3,024\u001b[0m â”‚ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation (\u001b[38;5;33mActivation\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m112\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m112\u001b[0m)    â”‚            \u001b[38;5;34m448\u001b[0m â”‚ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚         \u001b[38;5;34m50,176\u001b[0m â”‚ batch_normalization[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_1 (\u001b[38;5;33mActivation\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_1     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚          \u001b[38;5;34m1,792\u001b[0m â”‚ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚          \u001b[38;5;34m4,032\u001b[0m â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_2 (\u001b[38;5;33mActivation\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ depthwise_conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_2     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚          \u001b[38;5;34m1,792\u001b[0m â”‚ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2d  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m)            â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape (\u001b[38;5;33mReshape\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m448\u001b[0m)      â”‚              \u001b[38;5;34m0\u001b[0m â”‚ global_average_poolinâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m112\u001b[0m)      â”‚         \u001b[38;5;34m50,288\u001b[0m â”‚ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m448\u001b[0m)      â”‚         \u001b[38;5;34m50,624\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply (\u001b[38;5;33mMultiply\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m112\u001b[0m)    â”‚         \u001b[38;5;34m50,176\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_3     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m112\u001b[0m)    â”‚            \u001b[38;5;34m448\u001b[0m â”‚ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ stochastic_depth          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m112\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_3â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mStochasticDepth\u001b[0m)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚         \u001b[38;5;34m50,176\u001b[0m â”‚ stochastic_depth[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_3 (\u001b[38;5;33mActivation\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_4     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚          \u001b[38;5;34m1,792\u001b[0m â”‚ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d_1        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚          \u001b[38;5;34m4,032\u001b[0m â”‚ batch_normalization_4â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_4 (\u001b[38;5;33mActivation\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ depthwise_conv2d_1[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_5     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚          \u001b[38;5;34m1,792\u001b[0m â”‚ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2dâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m)            â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_5â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m448\u001b[0m)      â”‚              \u001b[38;5;34m0\u001b[0m â”‚ global_average_poolinâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m112\u001b[0m)      â”‚         \u001b[38;5;34m50,288\u001b[0m â”‚ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m448\u001b[0m)      â”‚         \u001b[38;5;34m50,624\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_1 (\u001b[38;5;33mMultiply\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_5â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m224\u001b[0m)    â”‚        \u001b[38;5;34m100,352\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_6     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m224\u001b[0m)    â”‚            \u001b[38;5;34m896\u001b[0m â”‚ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ stochastic_depth_1        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m224\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_6â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mStochasticDepth\u001b[0m)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m896\u001b[0m)    â”‚        \u001b[38;5;34m200,704\u001b[0m â”‚ stochastic_depth_1[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_5 (\u001b[38;5;33mActivation\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m896\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_7     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m896\u001b[0m)    â”‚          \u001b[38;5;34m3,584\u001b[0m â”‚ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d_2        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m896\u001b[0m)    â”‚          \u001b[38;5;34m8,064\u001b[0m â”‚ batch_normalization_7â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_6 (\u001b[38;5;33mActivation\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m896\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ depthwise_conv2d_2[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_8     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m896\u001b[0m)    â”‚          \u001b[38;5;34m3,584\u001b[0m â”‚ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2dâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m896\u001b[0m)            â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_8â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m896\u001b[0m)      â”‚              \u001b[38;5;34m0\u001b[0m â”‚ global_average_poolinâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m224\u001b[0m)      â”‚        \u001b[38;5;34m200,928\u001b[0m â”‚ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m896\u001b[0m)      â”‚        \u001b[38;5;34m201,600\u001b[0m â”‚ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_2 (\u001b[38;5;33mMultiply\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m896\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_8â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m896\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚        \u001b[38;5;34m401,408\u001b[0m â”‚ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_9     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚          \u001b[38;5;34m1,792\u001b[0m â”‚ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ stochastic_depth_2        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m448\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_9â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mStochasticDepth\u001b[0m)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m1792\u001b[0m)   â”‚        \u001b[38;5;34m802,816\u001b[0m â”‚ stochastic_depth_2[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_7 (\u001b[38;5;33mActivation\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m1792\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_10    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m1792\u001b[0m)   â”‚          \u001b[38;5;34m7,168\u001b[0m â”‚ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d_3        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m1792\u001b[0m)   â”‚         \u001b[38;5;34m16,128\u001b[0m â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_8 (\u001b[38;5;33mActivation\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m1792\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ depthwise_conv2d_3[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_11    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m1792\u001b[0m)   â”‚          \u001b[38;5;34m7,168\u001b[0m â”‚ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2dâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1792\u001b[0m)           â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_3 (\u001b[38;5;33mReshape\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1792\u001b[0m)     â”‚              \u001b[38;5;34m0\u001b[0m â”‚ global_average_poolinâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m448\u001b[0m)      â”‚        \u001b[38;5;34m803,264\u001b[0m â”‚ reshape_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1792\u001b[0m)     â”‚        \u001b[38;5;34m804,608\u001b[0m â”‚ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_3 (\u001b[38;5;33mMultiply\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m1792\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m1792\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ multiply_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m896\u001b[0m)    â”‚      \u001b[38;5;34m1,605,632\u001b[0m â”‚ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_12    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m896\u001b[0m)    â”‚          \u001b[38;5;34m3,584\u001b[0m â”‚ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ stochastic_depth_3        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m896\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mStochasticDepth\u001b[0m)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2dâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m896\u001b[0m)            â”‚              \u001b[38;5;34m0\u001b[0m â”‚ stochastic_depth_3[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              â”‚          \u001b[38;5;34m5,382\u001b[0m â”‚ global_average_poolinâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)              </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">        Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to           </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,024</span> â”‚ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)    â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> â”‚ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">50,176</span> â”‚ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_1     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> â”‚ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,032</span> â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ depthwise_conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_2     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> â”‚ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2d  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)            â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)      â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_poolinâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)      â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">50,288</span> â”‚ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)      â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">50,624</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_2â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">50,176</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_3     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)    â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> â”‚ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ stochastic_depth          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_3â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">StochasticDepth</span>)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">50,176</span> â”‚ stochastic_depth[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_4     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> â”‚ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d_1        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,032</span> â”‚ batch_normalization_4â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ depthwise_conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_5     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> â”‚ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2dâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)            â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_5â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)      â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_poolinâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)      â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">50,288</span> â”‚ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)      â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">50,624</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_5â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">100,352</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_6     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)    â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> â”‚ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ stochastic_depth_1        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_6â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">StochasticDepth</span>)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">200,704</span> â”‚ stochastic_depth_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_7     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> â”‚ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d_2        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,064</span> â”‚ batch_normalization_7â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ depthwise_conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_8     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> â”‚ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2dâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)            â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_8â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)      â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_poolinâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)      â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">200,928</span> â”‚ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)      â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">201,600</span> â”‚ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_8â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">401,408</span> â”‚ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_9     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> â”‚ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ stochastic_depth_2        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_9â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">StochasticDepth</span>)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">802,816</span> â”‚ stochastic_depth_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_10    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,168</span> â”‚ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ depthwise_conv2d_3        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)   â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,128</span> â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ depthwise_conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_11    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,168</span> â”‚ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2dâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)           â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)     â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_poolinâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)      â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">803,264</span> â”‚ reshape_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)     â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">804,608</span> â”‚ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multiply_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605,632</span> â”‚ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_12    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> â”‚ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ stochastic_depth_3        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalization_1â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">StochasticDepth</span>)         â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2dâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)            â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ stochastic_depth_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">5,382</span> â”‚ global_average_poolinâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,614,661\u001b[0m (63.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,614,661</span> (63.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,532,246\u001b[0m (21.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,532,246</span> (21.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m17,920\u001b[0m (70.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,920</span> (70.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m11,064,495\u001b[0m (42.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,064,495</span> (42.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create function that computes the heatmap using the gradients of the target class with respect to the output feature map of the last conv layer"
      ],
      "metadata": {
        "id": "XL1DXavKqeS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_conv_layer_name = 'conv2d_8'\n"
      ],
      "metadata": {
        "id": "5q28rVE5u1_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        loss = predictions[:, tf.argmax(predictions[0])]\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    max_heat = np.max(heatmap)\n",
        "    if max_heat == 0:\n",
        "        return heatmap\n",
        "    heatmap /= max_heat\n",
        "    return heatmap[0]\n"
      ],
      "metadata": {
        "id": "OxLbfbYvqceO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare image"
      ],
      "metadata": {
        "id": "RV2pDcsIrDQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select 4 random test images\n",
        "sample_test_images = test_df.sample(n=1)\n",
        "\n",
        "for _, row in sample_test_images.iterrows():\n",
        "    img_path = row['filepath']\n",
        "    label = row['Labels']\n",
        "\n",
        "    # Load and preprocess the image\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, img_size) / 255.0  # Normalize\n",
        "    img_array = np.expand_dims(img, axis=0)\n",
        "\n",
        "    preds = model.predict(img_array)\n",
        "    predicted_label = np.argmax(preds[0])\n",
        "\n",
        "    # Generate the Grad-CAM heatmap\n",
        "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "    # Display the image and the heatmap\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    # Original image\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Original Image\\nLabel: {label}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Heatmap\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(img)\n",
        "    plt.imshow(heatmap, cmap='jet', alpha=0.5)  # Overlay heatmap\n",
        "    plt.title(f\"Pred Label/True label \\n {predicted_label}/{label}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "gkID9PfYvCXD",
        "outputId": "ecd0602b-5f7c-43f0-8b8b-f386109e8864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'_PrefetchDataset' object has no attribute 'sample'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-ff037a24e9e2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Select 4 random test images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msample_test_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_test_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_test_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filepath'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_PrefetchDataset' object has no attribute 'sample'"
          ]
        }
      ]
    }
  ]
}